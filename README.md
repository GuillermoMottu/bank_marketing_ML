# Bank Marketing Decision Tree - Proyecto Completo

ImplementaciÃ³n completa de un sistema de predicciÃ³n de campaÃ±as bancarias usando **DecisionTreeClassifier** de scikit-learn, con API REST (FastAPI), base de datos PostgreSQL, dashboard de monitoreo (Dash), dockerizaciÃ³n completa, tests y documentaciÃ³n profesional.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un modelo de Machine Learning para predecir si un cliente suscribirÃ¡ un depÃ³sito a tÃ©rmino fijo basÃ¡ndose en informaciÃ³n demogrÃ¡fica y de comportamiento. El sistema incluye:

- **Preprocesamiento completo** con Pipeline y ColumnTransformer
- **Modelo DecisionTreeClassifier** optimizado con GridSearchCV
- **API REST** con FastAPI para predicciones y mÃ©tricas
- **Base de datos PostgreSQL** para almacenar histÃ³rico de mÃ©tricas y predicciones
- **Dashboard interactivo** con Dash y Plotly para monitoreo
- **Prueba de hipÃ³tesis estadÃ­stica** con prueba binomial exacta
- **DockerizaciÃ³n completa** para despliegue fÃ¡cil
- **Guardado automÃ¡tico** de todas las predicciones en la base de datos
- **Manejo robusto de errores** con mensajes claros y cÃ³digos HTTP apropiados

## ğŸ—ï¸ Estructura del Proyecto

```
bank-marketing-dt-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (bank.csv)
â”‚   â””â”€â”€ processed/              # Datos preprocesados
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb           # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ 02_hypothesis_test.ipynb  # Prueba de hipÃ³tesis
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/          # Pipeline de preprocesamiento
â”‚   â”œâ”€â”€ model/                  # Entrenamiento y evaluaciÃ³n
â”‚   â”œâ”€â”€ api/                    # API FastAPI
â”‚   â”œâ”€â”€ database/               # Modelos y conexiÃ³n PostgreSQL
â”‚   â”œâ”€â”€ dashboard/              # Dashboard Dash
â”‚   â””â”€â”€ utils/                  # Utilidades y configuraciÃ³n
â”œâ”€â”€ models/                     # Modelos entrenados (.pkl)
â”œâ”€â”€ tests/                      # Tests unitarios e integraciÃ³n
â”œâ”€â”€ docs/                       # DocumentaciÃ³n adicional
â”œâ”€â”€ docker/                     # Dockerfiles y docker-compose
â”œâ”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ train_model.py             # Script para entrenar el modelo
â””â”€â”€ README.md                  # Este archivo
```

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.11+
- Docker y Docker Compose (para despliegue con Docker)
- PostgreSQL 15+ (si se ejecuta sin Docker)

### InstalaciÃ³n Local

1. **Clonar el repositorio**:
```bash
git clone <repository-url>
cd bank-marketing-dt-project
```

2. **Crear entorno virtual**:
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**:
```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

5. **Entrenar el modelo** (primera vez):
```bash
python train_model.py
```

Esto crearÃ¡:
- `models/preprocessing_pipeline.pkl`
- `models/decision_tree_model.pkl`

**âš ï¸ Nota importante**: Si planeas usar Docker, es recomendable entrenar el modelo dentro del contenedor para asegurar compatibilidad de versiones:
```bash
docker-compose up -d api
docker exec bank_marketing_api python train_model.py
```

## ğŸ³ EjecuciÃ³n con Docker (Recomendado)

El mÃ©todo mÃ¡s simple para ejecutar todo el sistema es usando Docker Compose:

```bash
docker compose up --build
```

Esto iniciarÃ¡ automÃ¡ticamente:
- **PostgreSQL** en el puerto 5432
- **API FastAPI** en el puerto 8000
- **Dashboard Dash** en el puerto 8050

### Acceso a los Servicios

- **API**: http://localhost:8000
- **DocumentaciÃ³n API**: http://localhost:8000/docs
- **Dashboard**: http://localhost:8050

## ğŸ“¡ Endpoints de la API

### POST `/api/v1/predict`

Realiza una predicciÃ³n para un cliente. **Cada predicciÃ³n se guarda automÃ¡ticamente en la base de datos**.

**Request Body**:
```json
{
  "age": 59,
  "job": "admin.",
  "marital": "married",
  "education": "secondary",
  "default": "no",
  "balance": 2343.0,
  "housing": "yes",
  "loan": "no",
  "contact": "unknown",
  "day": 5,
  "month": "may",
  "duration": 1042,
  "campaign": 1,
  "pdays": -1,
  "previous": 0,
  "poutcome": "unknown"
}
```

**Response**:
```json
{
  "prediction": 1,
  "probability": 0.85,
  "class_name": "yes"
}
```

**Nota**: Cada predicciÃ³n se guarda automÃ¡ticamente en la tabla `prediction_history` con los datos de entrada, resultado y timestamp.

### GET `/api/v1/metrics`

Obtiene las mÃ©tricas actuales del modelo calculadas en el conjunto de test.

**Response**:
```json
{
  "model": "Decision Tree - Bank Marketing",
  "accuracy": 0.8567,
  "precision": 0.8234,
  "recall": 0.7891,
  "f1_score": 0.8059,
  "auc_roc": 0.9123,
  "confusion_matrix": [[1500, 200], [150, 800]],
  "classification_report": {...},
  "timestamp": "2025-11-25 19:00:00",
  "roc_curve": {...},
  "precision_recall_curve": {...}
}
```

**Nota**: Cada llamada a este endpoint guarda automÃ¡ticamente las mÃ©tricas en PostgreSQL.

### GET `/api/v1/health`

Health check de la API.

**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2025-11-25 19:00:00"
}
```

## ğŸ“Š Dashboard

El dashboard proporciona una interfaz web completa para:

### PestaÃ±a de MÃ©tricas

- **Tarjetas de mÃ©tricas actuales**: Accuracy, Precision, Recall, F1-Score, AUC-ROC
- **GrÃ¡ficos histÃ³ricos**: EvoluciÃ³n de todas las mÃ©tricas a lo largo del tiempo
- **Matriz de confusiÃ³n interactiva**: VisualizaciÃ³n en heatmap
- **Curvas ROC y Precision-Recall**: Del Ãºltimo cÃ¡lculo de mÃ©tricas
- **Tabla histÃ³rica completa**: Todas las mÃ©tricas guardadas en la base de datos

### PestaÃ±a de PredicciÃ³n

- **Formulario interactivo**: Para ingresar caracterÃ­sticas del cliente
- **PredicciÃ³n en tiempo real**: Muestra probabilidad y clase predicha
- **ValidaciÃ³n de entrada**: Asegura datos correctos antes de predecir
- **Guardado automÃ¡tico**: Cada predicciÃ³n se guarda automÃ¡ticamente en la base de datos

El dashboard se actualiza automÃ¡ticamente cada 30 segundos y maneja correctamente las operaciones concurrentes de base de datos.

**Consejos para mejores resultados:**
- Usar `default="no"` y `loan="no"` aumenta significativamente las probabilidades
- Contactos por `cellular` tienen mejor tasa de Ã©xito
- DuraciÃ³n alta (>400 segundos) indica mayor interÃ©s
- Si hay historial previo, `poutcome="success"` es muy positivo

## ğŸ“ˆ Prueba de HipÃ³tesis EstadÃ­stica

El proyecto incluye una prueba de hipÃ³tesis estadÃ­stica completa para validar que el modelo es significativamente mejor que el azar:

### HipÃ³tesis

- **H0**: Accuracy â‰¤ 0.5 (rendimiento no mejor que el azar)
- **H1**: Accuracy > 0.5 (modelo es mejor que el azar)

### ImplementaciÃ³n

Se utiliza una **prueba binomial exacta** (`scipy.stats.binomtest`) con:

- Nivel de significancia: Î± = 0.05
- Alternativa: one-sided (greater)
- P-value calculado y decisiÃ³n automÃ¡tica

### Errores Tipo I y Tipo II

- **Error Tipo I (Î±)**: Rechazar H0 cuando es verdadera â†’ Concluir que el modelo es mejor cuando no lo es
- **Error Tipo II (Î²)**: No rechazar H0 cuando H1 es verdadera â†’ No detectar que el modelo es Ãºtil

Ver el notebook `notebooks/02_hypothesis_test.ipynb` para detalles completos.

## ğŸ§ª Tests

Ejecutar los tests:

```bash
pytest tests/ -v
```

Con cobertura:

```bash
pytest tests/ --cov=src --cov-report=html
```

La cobertura mÃ­nima objetivo es **80%**.

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Crear un archivo `.env` con:

```env
# Database
DB_HOST=db
DB_PORT=5432
DB_NAME=bank_marketing
DB_USER=postgres
DB_PASSWORD=postgres

# API
API_HOST=0.0.0.0
API_PORT=8000

# Dashboard
DASHBOARD_HOST=0.0.0.0
DASHBOARD_PORT=8050
```

## ğŸ“š Uso del Modelo

### Entrenamiento

Para entrenar o reentrenar el modelo:

```bash
python train_model.py
```

El script realiza:
1. Carga de datos desde `data/raw/bank.csv`
2. CreaciÃ³n y ajuste del pipeline de preprocesamiento
3. DivisiÃ³n train/test estratificada (80/20)
4. OptimizaciÃ³n de hiperparÃ¡metros con GridSearchCV (cv=10)
5. Guardado del modelo y pipeline

### PredicciÃ³n desde Python

```python
from src.api.dependencies import ModelService

# Cargar servicio
service = ModelService()

# Hacer predicciÃ³n
input_data = {
    "age": 59,
    "job": "admin.",
    # ... resto de campos
}
prediction, probability = service.predict(input_data)
print(f"PredicciÃ³n: {prediction}, Probabilidad: {probability}")
```

## ğŸ—„ï¸ Base de Datos

La base de datos PostgreSQL utiliza SQLAlchemy async y almacena automÃ¡ticamente:

### Tabla `metrics_history`

Almacena el histÃ³rico de mÃ©tricas del modelo:

```sql
CREATE TABLE metrics_history (
    id SERIAL PRIMARY KEY,
    model_name VARCHAR(255),
    metrics_json JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**CaracterÃ­sticas:**
- Cada vez que se llama al endpoint `/metrics`, se crea un nuevo registro
- Almacena mÃ©tricas completas: accuracy, precision, recall, F1-score, AUC-ROC, matriz de confusiÃ³n, curvas ROC y Precision-Recall
- Permite seguimiento histÃ³rico del rendimiento del modelo

### Tabla `prediction_history`

Almacena el histÃ³rico de todas las predicciones realizadas:

```sql
CREATE TABLE prediction_history (
    id SERIAL PRIMARY KEY,
    input_data JSONB NOT NULL,
    prediction INTEGER NOT NULL,
    probability VARCHAR(20) NOT NULL,
    class_name VARCHAR(10) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**CaracterÃ­sticas:**
- Guardado automÃ¡tico de cada predicciÃ³n realizada
- Incluye datos de entrada completos del cliente en formato JSON
- Permite auditorÃ­a y anÃ¡lisis posterior del comportamiento del modelo
- Facilita el seguimiento de predicciones exitosas vs. fallidas

**Pool de conexiones:**
- Configurado para manejar mÃºltiples operaciones concurrentes
- `pool_pre_ping=True` para verificar conexiones vivas
- Reciclaje automÃ¡tico de conexiones

### Consultar Historial

Para consultar el historial de predicciones desde Python:

```python
import asyncio
from src.database.connection import AsyncSessionLocal
from src.database.crud import get_all_predictions

async def consultar_predicciones():
    async with AsyncSessionLocal() as session:
        predicciones = await get_all_predictions(session, limit=100)
        for pred in predicciones[:10]:
            print(f"ID: {pred.id}, PredicciÃ³n: {pred.class_name}, "
                  f"Probabilidad: {pred.probability}, Fecha: {pred.created_at}")

asyncio.run(consultar_predicciones())
```

O directamente desde PostgreSQL:

```sql
-- Ver Ãºltimas 10 predicciones
SELECT id, prediction, probability, class_name, created_at 
FROM prediction_history 
ORDER BY created_at DESC 
LIMIT 10;

-- Contar predicciones por clase
SELECT class_name, COUNT(*) 
FROM prediction_history 
GROUP BY class_name;

-- Ver predicciones con alta probabilidad
SELECT * FROM prediction_history 
WHERE probability::float > 0.8 
ORDER BY created_at DESC;
```

## ğŸ” Preprocesamiento

El pipeline de preprocesamiento incluye:

1. **Manejo de valores "unknown"**: Convertidos a categorÃ­as propias (`unknown_<columna>`)
2. **One-Hot Encoding**: Para variables categÃ³ricas (job, marital, education, etc.)
3. **RobustScaler**: Para variables numÃ©ricas (age, balance, duration, etc.)
4. **ColumnTransformer**: Organiza las transformaciones por tipo de columna

## ğŸ¯ HiperparÃ¡metros Optimizados

El GridSearchCV optimiza:

- `max_depth`: [5, 10, 15, 20, None]
- `min_samples_split`: [2, 5, 10, 20]
- `min_samples_leaf`: [1, 2, 4, 8]
- `criterion`: ['gini', 'entropy']
- `class_weight`: [None, 'balanced']

Con validaciÃ³n cruzada de **10 folds** y scoring **ROC-AUC**.

## ğŸ“ Notas TÃ©cnicas

- **Reproducibilidad**: `random_state=42` en todas las operaciones aleatorias
- **DivisiÃ³n estratificada**: Para mantener proporciones de clases en train/test
- **ValidaciÃ³n cruzada**: 10 folds para GridSearchCV
- **Scoring**: ROC-AUC (mejor para datasets potencialmente desbalanceados)
- **Manejo de errores**: Sistema robusto con cÃ³digos HTTP apropiados (500 para errores internos, 503 para servicio no disponible)
- **Operaciones asÃ­ncronas**: Base de datos con SQLAlchemy async para mejor rendimiento
- **IsolaciÃ³n de event loops**: Dashboard con manejo correcto de operaciones asÃ­ncronas en contexto sÃ­ncrono

## ğŸ› Troubleshooting

### El modelo no se encuentra

**OpciÃ³n 1 - Entrenar localmente:**
```bash
python train_model.py
```

**OpciÃ³n 2 - Entrenar dentro del contenedor Docker (recomendado):**
```bash
docker exec bank_marketing_api python train_model.py
```

Esto asegura que el modelo se entrene con la misma versiÃ³n de scikit-learn que usa la API.

### Error 503 Service Unavailable en predicciones

Este error indica que el modelo no estÃ¡ disponible. Verifica:
1. Que el modelo existe en `models/decision_tree_model.pkl`
2. Que el pipeline existe en `models/preprocessing_pipeline.pkl`
3. Si estÃ¡s usando Docker, entrena el modelo dentro del contenedor para evitar problemas de versiones

### Error de conexiÃ³n a la base de datos

Verifica que PostgreSQL estÃ© corriendo y que las variables de entorno estÃ©n correctamente configuradas:

```bash
docker ps  # Verificar que el contenedor de la BD estÃ© corriendo
docker logs bank_marketing_db  # Ver logs de la base de datos
```

### Dashboard no muestra datos

1. AsegÃºrate de haber llamado al menos una vez al endpoint `/metrics` para generar datos histÃ³ricos
2. El dashboard se actualiza automÃ¡ticamente cada 30 segundos
3. Si hay errores de concurrencia, los contenedores ya estÃ¡n configurados para manejarlos correctamente

### Error de versiones de scikit-learn

Si entrenaste el modelo localmente y obtienes errores al cargarlo en Docker:
- Entrena el modelo dentro del contenedor Docker para asegurar compatibilidad de versiones
- Ejecuta: `docker exec bank_marketing_api python train_model.py`

### Reconstruir imÃ¡genes Docker despuÃ©s de cambios en el cÃ³digo

Si has hecho cambios en el cÃ³digo y necesitas reconstruir las imÃ¡genes:

```bash
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

## ğŸ“„ Licencia

Este proyecto es acadÃ©mico y cumple con los requisitos del documento sprint.pdf y las especificaciones del profesor.

## ğŸ‘¥ Autor

Proyecto desarrollado como parte de un curso acadÃ©mico de Machine Learning y MLOps.

---

## âœ¨ CaracterÃ­sticas Adicionales

### Guardado AutomÃ¡tico de Predicciones

Todas las predicciones se guardan automÃ¡ticamente en la base de datos, permitiendo:
- AuditorÃ­a completa de todas las predicciones realizadas
- AnÃ¡lisis de patrones en las predicciones
- Seguimiento de la efectividad del modelo en producciÃ³n
- AnÃ¡lisis de quÃ© caracterÃ­sticas llevan a predicciones exitosas

### Manejo Robusto de Errores

El sistema incluye manejo avanzado de errores:
- VerificaciÃ³n de disponibilidad del modelo antes de predecir
- Mensajes de error claros y descriptivos
- CÃ³digos HTTP apropiados (503 para servicio no disponible)
- Logging detallado para debugging

### Compatibilidad de Versiones

El sistema detecta y previene problemas de compatibilidad:
- VerificaciÃ³n de versiones de scikit-learn
- RecomendaciÃ³n de entrenar el modelo dentro del contenedor Docker
- Mensajes claros cuando el modelo no estÃ¡ disponible

---

**Â¡El proyecto estÃ¡ listo para ejecutarse con `docker compose up --build`!** ğŸš€

**Nota**: AsegÃºrate de entrenar el modelo dentro del contenedor Docker para evitar problemas de compatibilidad de versiones.

